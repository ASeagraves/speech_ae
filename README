This package implements autoencoders for processing speech data in the time domain.  

Developer:  Andrew Seagraves
            2020

Contents:
build_speech_dict.py
-Driver to build a speech_dict ("speech dictionary") from a LibriSpeech corpus.  The speech_dict data structure forms the basis for the DataGenerator class implemented in generator.py.

utilities.py
-A set of utility functions for preprocessing, loading data from, and manipulating a LibriSpeech corpus.  Includes function for speech_dict construction.

generator.py
-DataGenerator class for generating batches of speech audio sequences from a preprocessed LibriSpeech corpus.

train.py
-Keras/TensorFlow implementation of a simple autoencoder using fully-connected layers built using Sequential().  The hyperparameters and network structure (number of layers and layer sizes) are passed as inputs enabling automated parameter studies.  The model is constructed in autoencoder.py.

driver.py
-Driver for conducting automated parameter studies via sequential calls to train.py.

plot_spectrogram.py
-Driver for plotting batches of reconstructed spectrograms from trained models and comparing them to ground truth.


Notes:
-The current implementation supports a sliding window over the input training sequence with a specified amount of overlap on the left and right.  The chunk size and left/right overlap size are specified in the time domain.  The user must also specify the sampling rate.


Dependencies:
-numpy
-TensorFlow (v1 or 2)
-librosa
-tqdm
-matplotlib


To Train a Model on a LibriSpeech Corpus:
1.  Edit root_dir path in build_speech_dict.py to point to LibriSpeech data directory
2.  Run python build_speech_dict.py
3.  Edit paths in driver.py (root_dir, base_dir, etc.).  Set desired hyperparameters and network/layer sizes for training.
4.  Run python driver.py
